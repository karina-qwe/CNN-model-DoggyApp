{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a99bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "\n",
    "import coremltools\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4214c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '70-dog-breeds/train'\n",
    "TEST_DIR = '70-dog-breeds/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input,\n",
    "    validation_split = 0.2\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68969cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6390 images belonging to 70 classes.\n",
      "Found 1556 images belonging to 70 classes.\n",
      "Found 700 images belonging to 70 classes.\n"
     ]
    }
   ],
   "source": [
    "# Split the data into three categories.\n",
    "train_images = train_generator.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30be627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize Layer\n",
    "resize_and_rescale = keras.Sequential([\n",
    "  preprocessing.Resizing(224,224),\n",
    "  preprocessing.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "# Setup data augmentation\n",
    "data_augmentation = keras.Sequential([\n",
    "  preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  preprocessing.RandomRotation(0.2),\n",
    "  preprocessing.RandomZoom(0.2),\n",
    "  preprocessing.RandomHeight(0.2),\n",
    "  preprocessing.RandomWidth(0.2),                       \n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345d6555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# Load the pretained model\n",
    "pretrained_model = MobileNetV3Large(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "print(len(train_images))\n",
    "print(len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee0c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "inputs = pretrained_model.input\n",
    "x = resize_and_rescale(inputs)\n",
    "x = data_augmentation(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(pretrained_model.output)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "outputs = Dense(70, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(0.0001),\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bd32d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint callback\n",
    "checkpoint_path = \"./Finish CNN-Model/Checkpoint\"\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "                                      save_weights_only=True,\n",
    "                                      monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True)\n",
    "\n",
    "\n",
    "# Create callback to visualize data\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./Finish CNN-Model/Graph', \n",
    "                                             histogram_freq=1, write_graph=True, \n",
    "                                             write_images=True, embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a7ab529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 41s 193ms/step - loss: 3.3345 - accuracy: 0.2340 - val_loss: 1.6901 - val_accuracy: 0.7114\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 1.4209 - accuracy: 0.6599 - val_loss: 0.6661 - val_accuracy: 0.8400\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.8272 - accuracy: 0.7806 - val_loss: 0.4990 - val_accuracy: 0.8605\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.6285 - accuracy: 0.8219 - val_loss: 0.4281 - val_accuracy: 0.8760\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.5200 - accuracy: 0.8474 - val_loss: 0.3918 - val_accuracy: 0.8760\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.4418 - accuracy: 0.8726 - val_loss: 0.3816 - val_accuracy: 0.8811\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.3893 - accuracy: 0.8890 - val_loss: 0.3690 - val_accuracy: 0.8824\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.3562 - accuracy: 0.8936 - val_loss: 0.3631 - val_accuracy: 0.8940\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.3175 - accuracy: 0.9086 - val_loss: 0.3529 - val_accuracy: 0.8914\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 0.2897 - accuracy: 0.9141 - val_loss: 0.3474 - val_accuracy: 0.8920\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.2707 - accuracy: 0.9169 - val_loss: 0.3468 - val_accuracy: 0.9023\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.2504 - accuracy: 0.9264 - val_loss: 0.3363 - val_accuracy: 0.8985\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.2368 - accuracy: 0.9264 - val_loss: 0.3269 - val_accuracy: 0.9010\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.2179 - accuracy: 0.9322 - val_loss: 0.3328 - val_accuracy: 0.8997\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.2027 - accuracy: 0.9376 - val_loss: 0.3321 - val_accuracy: 0.9030\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.1937 - accuracy: 0.9397 - val_loss: 0.3252 - val_accuracy: 0.9042\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.1755 - accuracy: 0.9460 - val_loss: 0.3274 - val_accuracy: 0.9036\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.1649 - accuracy: 0.9487 - val_loss: 0.3298 - val_accuracy: 0.9030\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.1514 - accuracy: 0.9505 - val_loss: 0.3239 - val_accuracy: 0.9068\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.1471 - accuracy: 0.9538 - val_loss: 0.3316 - val_accuracy: 0.9068\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.1321 - accuracy: 0.9595 - val_loss: 0.3278 - val_accuracy: 0.9100\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 43s 218ms/step - loss: 0.1284 - accuracy: 0.9624 - val_loss: 0.3309 - val_accuracy: 0.9042\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 0.1188 - accuracy: 0.9643 - val_loss: 0.3356 - val_accuracy: 0.9075\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 0.1089 - accuracy: 0.9693 - val_loss: 0.3352 - val_accuracy: 0.9120\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    steps_per_epoch=len(train_images),\n",
    "    validation_data=val_images,\n",
    "    validation_steps=len(val_images),\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience = 5),\n",
    "        tb_callback,\n",
    "        checkpoint_callback,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f159b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Train Loss: 0.03558\n",
      "Train Accuracy: 99.20%\n",
      "    Valid Loss: 0.33518\n",
      "Valid Accuracy: 91.20%\n",
      "    Test Loss: 0.10656\n",
      "Test Accuracy: 97.00%\n"
     ]
    }
   ],
   "source": [
    "# Show metrics\n",
    "train_acc, train_loss = model.evaluate(train_images, verbose=0)\n",
    "val_acc, val_loss = model.evaluate(val_images, verbose=0)\n",
    "test_acc, test_loss = model.evaluate(test_images, verbose=0)\n",
    "print(\"    Train Loss: {:.5f}\".format(train_acc))\n",
    "print(\"Train Accuracy: {:.2f}%\".format(train_loss * 100))\n",
    "print(\"    Valid Loss: {:.5f}\".format(val_acc))\n",
    "print(\"Valid Accuracy: {:.2f}%\".format(val_loss * 100))\n",
    "print(\"    Test Loss: {:.5f}\".format(test_acc))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_loss * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cec26f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7643225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
